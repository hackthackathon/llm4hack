# Ethical Considerations 

*some of this section needs to be cleaned up and changed to markdown*

Based on the papers below here are 5 ethical considerations:

1. Bias in Outputs LLMs may produce outputs that reflect inherent biases in their training data, which can unintentionally perpetuate stereotypes or inequalities in hackathon solutions​ [ar5iv](https://ar5iv.org/abs/2406.11400) [ar5iv](https://ar5iv.org/abs/2306.06283)
2. Transparency in Usage Hackathon teams should clearly communicate how LLMs are used, ensuring participants and stakeholders understand AI's role in generating ideas or solutions​ [ar5iv](https://ar5iv.org/abs/2405.14445) [ar5iv](https://ar5iv.org/abs/2306.06283)
2a Is there an element of "shaming" with admitting to LLM use? Is there a way to survey anonymously to avoid the double bind
2b Organizers should provide guidance on LLM use including ethical considerations. This serves as an opportunity for education around ethical use of LLMs.
2c The user is still responsible for outputs, 

3. Over-reliance on AI Excessive dependence on LLMs can lead to reduced critical thinking or failure to scrutinize AI-generated outputs, especially when data accuracy is crucial [ar5iv] (https://ar5iv.org/pdf/2405.14445) [ar5iv](https://ar5iv.org/pdf/2306.06283v3)
4. Safety and Misinformation LLMs can produce incorrect or misleading information if not properly guided, posing risks in sensitive fields like healthcare, education, or scientific research [ar5iv](https://ar5iv.org/abs/2406.11400) [ar5iv](https://ar5iv.org/pdf/2306.06283v3)
5. Ethical Accessibility LLM-based tools should be designed to ensure inclusivity and fairness, avoiding barriers for less technically proficient participants or marginalized groups​ [ar5iv](https://ar5iv.org/abs/2406.11400) [ar5iv](https://ar5iv.org/pdf/2306.06283v3)
	5a groups with paid subscriptions might have access to better models and have an advantage
.

5 papers on arXiv that have “LLMs” and “hackathon” in the abstract:
arXiv:2408.08878  [pdf, other]  Knowledge Prompting: How Knowledge Engineers Use Large Language Models
Authors: Elisavet Koutsiana et al.
Submitted 2 August, 2024; originally announced August 2024.
arXiv:2406.11400  [pdf, other]  cs.CL astro-ph.IM Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation
Authors: Golnaz Shapurian
Submitted 17 June, 2024; originally announced June 2024.
arXiv:2405.14445  [pdf]  cs.CL cs.AI Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study
Authors: Lena Schmidt et al. 
Abstract: This paper describes a rapid feasibility study of using GPT-4, a large
Journal ref: Proceedings of the 3rd Workshop on Augmented Intelligence for Technology-Assisted Reviews Systems, 2024
arXiv:2404.18479  [pdf]  cs.HC ChatGPT as an inventor: Eliciting the strengths and weaknesses of current large language models against humans in engineering design
Authors: Daniel Nygård Ege et al.
Submitted 29 April, 2024; originally announced April 2024.
arXiv:2306.06283  [pdf, other]  cond-mat.mtrl-sci cs.LG physics.chem-ph 14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon
Authors: Kevin Maik Jablonka et al.
Submitted 14 July, 2023; v1 submitted 9 June, 2023; originally announced June 2023.

